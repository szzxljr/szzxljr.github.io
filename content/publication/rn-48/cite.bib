@inproceedings{RN48,
 abstract = {The rapid evolution of machine learning and computer vision has given rise to numerous new tasks, primarily driven by deep convolutional neural networks’ ability to create complex mappings between feature space X and label space Y. These tasks often necessitate large-scale, human-labeled datasets for supervised training of the network. However, manual labeling is both costly and time-consuming. To overcome this hurdle, it is imperative to develop algorithms that can leverage existing labeled datasets to extract knowledge about the target domain. While most prior research has focused on single-source transfer learning, our study delves into multi-source transfer across various domains and tasks. The paper presents an improved cross-domain data analytics model that supports multi-source transfer learning by training a classifier to re-weight different sources and adjusting the rich and intricate information among sources to boost target learning. Experiments involving two source domains transferring to a single target domain showcase the effectiveness of our methodology. The model’s potential applications in image recognition include object recognition, medical imaging diagnosis, and so on. Future research could explore the scalability of the model to accommodate larger datasets and further refine the transfer learning process for more efficient knowledge extraction.},
 author = {Li, Jiarong and Wang, Jingge and Wang, Jingyang and Xu, Chihan and Wang, Hao and Zhang, Chaobo and Liang, Xiaojun and Ding, Wenbo and Gui, Weihua},
 doi = {10.1007/978-981-96-4506-0_13},
 isbn = {978-981-96-4506-0},
 keywords = {Multi-source Transfer Learning, Deep Learning, Convolutional Neural Network, Image Classification},
 pages = {207-222},
 publisher = {Springer Nature Singapore},
 series = {Cyberspace Simulation and Evaluation},
 title = {Enhancing cross-domain data analytics through multi-source transfer learning},
 url = {https://doi.org/10.1007/978-981-96-4506-0_13},
 year = {2025}
}
