@inproceedings{RN54,
   author = {Li, Jiarong},
   title = {PhD forum abstract: Ubiquitous sensing system for activity and gesture recognition via optical and energy-harvesting technologies},
   booktitle = {2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)},
   pages = {323-324},
   abstract = {This research focuses on ubiquitous sensing systems for activity and gesture recognition through novel optical sensing and energy harvesting technologies such as triboelectric nanogenerators (TENG), solar cells, and visible light communication (VLC). The primary goal is to address the limitations of existing sensing systems by creating a low-cost, energy-efficient, comprehensive solution that enhances sensor integration and communication. Thus, this study utilizes TENG for contact sensing, solar cells for non-contact sensing, and VLC for spatial sensing. The applied methodologies achieve activity and gesture recognition, with accuracies up to 99.4% and 97.3%, respectively. This work has potential applications in smart home automation, health monitoring, and intelligent control by providing a more sustainable and user-friendly approach to ubiquitous sensing.},
   keywords = {Ubiquitous Sensing, Optical Sensing, Energy Harvesting, Human-Computer Interaction},
   DOI = {10.1109/IPSN61024.2024.00062},
   year = {2024}
}

@inproceedings{RN58,
   author = {Li, Jiarong and Ge, Changshuo and Tao, Jun and Wang, Jingyang and Xu, Xiaomin and Chen, Xinlei and Gui, Weihua and Liang, Xiaojun and Ding, Wenbo},
   title = {SolareSkin: Self-powered visible light sensing through a solar cell e-skin},
   booktitle = {Adjunct Proceedings of the 2023 ACM International Joint Conference on Pervasive and Ubiquitous Computing & the 2023 ACM International Symposium on Wearable Computing},
   publisher = {Association for Computing Machinery},
   pages = {664–669},
   abstract = {SolareSkin is a self-powered and ubiquitous electronic skin equipped with ultraflexible organic solar cells for visible light sensing and energy harvesting. This dual-functional system captures light signals, transforms them into electrical impulses and enables multi-class gesture and activity recognition. Its design employs a photocurrent model that allows solar cells to serve as energy harvesters and visible light sensors simultaneously. The solar cells demonstrate a decent conversion rate of incident light into electricity, supporting an efficient, sustainable operation. Additionally, the system incorporates advanced system integration with a low-powered data collection board embedded with wireless transmission modules and an intuitive user interface. An algorithm is employed for signal analysis with data pre-processing methods and several machine learning models. The data pre-processing methods comprise filtering, scaling, normalization, segmentation, and downsampling of raw sensor data to reduce noise and increase prediction accuracy. The machine learning model evaluation focuses on three algorithms: Support Vector Machines (SVM), K-Nearest Neighbors (KNN), and Random Forest, due to their efficiency with high-dimensional, nonlinear data. The experimental results suggest the excellent performance of SVM in recognizing 7-class finger gestures and 7-class body activities, with accuracies of 97.3% and 96.7%, respectively. This advancement in electronic skin technology is promising for ubiquitous human-centric sensing, enabling various applications such as healthcare monitoring, human-computer interaction, and smart homes.},
   keywords = {Electronic Skin, Energy harvesting, Human activity recognition, Visible light sensing},
   DOI = {10.1145/3594739.3612904},
   url = {https://doi.org/10.1145/3594739.3612904},
   year = {2023}
}

@inproceedings{RN47,
   author = {Li, Jiarong and Ge, Changshuo and Xu, Chihan and Gong, Junhao and Gui, Weihua and Zhang, Chaobo and Liang, Xiaojun and Ding, Wenbo},
   title = {VLocSense: Integrated VLC system for indoor passive localization and human sensing},
   booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
   publisher = {Association for Computing Machinery},
   pages = {2022–2027},
   abstract = {The demand for accurate and real-time indoor localization and human sensing is rising with the development of smart environments, with applications in security and smart homes. Effective systems enhance safety, energy efficiency, and user experience by leveraging existing infrastructure, reducing deployment costs, and integrating seamlessly. Traditional methods rely on dedicated hardware, while communication or lighting infrastructure can provide dual-purpose solutions. This research focuses on Visible Light Communication (VLC) technology, which uses visible light for data transmission. Our VLC system utilizes existing lighting infrastructure to transmit data, providing localization and human sensing functionalities. The system design strategically incorporates specific VLC transmitters and receivers to enhance sensing performance. The collected data is processed using advanced algorithms and machine learning models, ensuring robust, real-time, and cost-effective localization with an accuracy of 96.6\% and human activity recognition with an accuracy of 98.3\%. This multi-functionality system demonstrates the potential for VLC in healthcare monitoring and home automation applications.},
   keywords = {visible light communication, indoor localization, human sensing, multi-functionality},
   DOI = {10.1145/3636534.3694729},
   url = {https://doi.org/10.1145/3636534.3694729},
   year = {2024}
}

@inproceedings{RN53,
   author = {Li, Jiarong and Liang, Chenxin and Xie, Zixuan and Liang, Xiaojun and Ding, Wenbo and Song, Jian and Zhang, Xiao-Ping},
   title = {Poster: Real-time material and texture recognition using visible light communication},
   booktitle = {Proceedings of the 22nd Annual International Conference on Mobile Systems, Applications and Services},
   publisher = {Association for Computing Machinery},
   pages = {696–697},
   abstract = {In response to the challenges presented by conventional material and texture recognition methods, our research introduces a system using visible light communication (VLC) technology. This approach provides a non-contact, non-destructive, dual-functional solution, overcoming the limitations of cost, safety, and environmental adaptability associated with traditional methods. Through a comprehensive design integrating hardware and software, our system utilizes VLC for precise and efficient recognition. Extensive testing confirms its effectiveness, achieving 97.7% accuracy in material identification and 93.8% in texture detection. This study highlights VLC's potential in enhancing automated recognition systems across various applications.},
   keywords = {visible light communication, material classification, texture recognition, machine learning},
   DOI = {10.1145/3643832.3661427},
   url = {https://doi.org/10.1145/3643832.3661427},
   year = {2024}
}

@inproceedings{RN48,
   author = {Li, Jiarong and Wang, Jingge and Wang, Jingyang and Xu, Chihan and Wang, Hao and Zhang, Chaobo and Liang, Xiaojun and Ding, Wenbo and Gui, Weihua},
   title = {Enhancing cross-domain data analytics through multi-source transfer learning},
   series = {Cyberspace Simulation and Evaluation},
   publisher = {Springer Nature Singapore},
   pages = {207-222},
   abstract = {The rapid evolution of machine learning and computer vision has given rise to numerous new tasks, primarily driven by deep convolutional neural networks’ ability to create complex mappings between feature space X and label space Y. These tasks often necessitate large-scale, human-labeled datasets for supervised training of the network. However, manual labeling is both costly and time-consuming. To overcome this hurdle, it is imperative to develop algorithms that can leverage existing labeled datasets to extract knowledge about the target domain. While most prior research has focused on single-source transfer learning, our study delves into multi-source transfer across various domains and tasks. The paper presents an improved cross-domain data analytics model that supports multi-source transfer learning by training a classifier to re-weight different sources and adjusting the rich and intricate information among sources to boost target learning. Experiments involving two source domains transferring to a single target domain showcase the effectiveness of our methodology. The model’s potential applications in image recognition include object recognition, medical imaging diagnosis, and so on. Future research could explore the scalability of the model to accommodate larger datasets and further refine the transfer learning process for more efficient knowledge extraction.},
   keywords = {Multi-source Transfer Learning, Deep Learning, Convolutional Neural Network, Image Classification},
   ISBN = {978-981-96-4506-0},
   DOI = {10.1007/978-981-96-4506-0_13},
   url = {https://doi.org/10.1007/978-981-96-4506-0_13},
   year = {2025}
}

@inproceedings{RN61,
   author = {Li, Jiarong and Wang, Zihan and Zhao, Zihao and Jin, Yuchao and Yin, Jihong and Huang, Shao-Lun and Wang, Jiyu},
   title = {TriboGait: A deep learning enabled triboelectric gait sensor system for human activity recognition and individual identification},
   booktitle = {Adjunct Proceedings of the 2021 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2021 ACM International Symposium on Wearable Computers},
   publisher = {Association for Computing Machinery},
   pages = {643–648},
   abstract = {Accurately and continuously measuring and collecting data on human gait is critical for human activity recognition and individual identification, enabling various applications in smart homes/buildings, including security authentication, personal healthcare, and intelligent automation. Many sensing technologies have been investigated by researchers recently, such as camera-based, laser-based, and mobile approaches, which have limitations in particular sensing situations, such as environments with fewer privacy concerns, line-of-sight, and the use of wearables, etc. On the other hand, the floor with the embedded sensor is stable and robust to different circumstances, enabling non-intrusive gait recognition and human identification. Therefore, a triboelectric nanogenerator (TENG)-based gait sensor system installed on the floor is proposed in this paper. Our approach has many advantages in comparison to the existing gait recognition systems, including low cost, simple fabrication, lightweight, and high durability. The TENG-based sensors can be simply embedded into a smart carpet to discern mechanical motions through electrical signals. Furthermore, a deep learning model, deep residual bidirectional long short-term memory network with dense layers (Residual Dense-BiLSTM), is proposed for multichannel floor-based gait recognition. By utilizing this model to analyze the electrical outputs, our system can accurately detect various human activities and distinguish different individuals’ walking patterns, with a recognition rate over 98% and 97%, respectively. We conclude that the proposed deep learning enabled triboelectric gait sensor system has broad applications in security and healthcare.},
   keywords = {human identification, floor sensor, deep learning, activity recognition},
   DOI = {10.1145/3460418.3480410},
   url = {https://doi.org/10.1145/3460418.3480410},
   year = {2021}
}

@article{RN63,
   author = {Li, Jiarong and Wu, Changsheng and Dharmasena, Ishara and Ni, Xiaoyue and Wang, Zihan and Shen, Haixu and Huang, Shao-Lun and Ding, Wenbo},
   title = {Triboelectric nanogenerators enabled internet of things: A survey},
   journal = {Intelligent and Converged Networks},
   volume = {1},
   number = {2},
   pages = {115-141},
   abstract = {As pioneering information technology, the Internet of Things (loT) targets at building an infrastructure of embedded devices and networks of connected objects, to offer omnipresent ecosystem and interaction across billions of smart devices, sensors, and actuators. The deployment of IoT calls for decentralized power supplies, self-powered sensors, and wireless transmission technologies, which have brought both opportunities and challenges to the existing solutions, especially when the network scales up. The Triboelectric Nanogenerators (TENGs), recently developed for mechanical energy harvesting and mechanical-to-electrical signal conversion, have the natural properties of energy and information, which have demonstrated high potentials in various applications of IoT. This context provides a comprehensive review of TENG enabled IoT and discusses the most popular and significant divisions. Firstly, the basic principle of TENG is re-examined in this article. Subsequently, a comprehensive and detailed review is given to the concept of IoT, followed by the scientific development of the TENG enabled IoT. Finally, the future of this evolving area is addressed.},
   keywords = {Triboelectric Nanogenerator (TENG), Internet of Things (IoT), energy harvesting, sensing system, smart cities},
   ISSN = {2708-6240},
   DOI = {10.23919/ICN.2020.0008},
   url = {https://ieeexplore.ieee.org/abstract/document/9310742},
   year = {2020}
}

@inproceedings{RN65,
   author = {Li, Jiarong and Wu, Xiang and Li, Qiuying and Li, Yefeng},
   title = {Finite-time distributed event-triggered consensus control for leader-following general linear multi-agent systems},
   booktitle = {2018 IEEE 3rd Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)},
   pages = {1974-1978},
   abstract = {In this paper, we study the finite-time containment consensus problem for multi-agent systems with general linear dynamics. Finite time consensus can reach consensus faster and have better disturbance rejection properties compared with conventional asymptotic consensus. Hence, we propose a distributed, independent and asynchronous event-triggered control protocol with leaders. We demonstrate that each follower agent can achieve consensus to the convex hull spanned by the leaders' agents in a certain time regardless of the initial condition under this event-triggered control strategy.},
   keywords = {Consensus, Decentralized Event-triggering, Multi-Agent System, General linear dynamics, Finite-time},
   ISBN = {2381-0947},
   DOI = {10.1109/IAEAC.2018.8577762},
   url = {https://ieeexplore.ieee.org/abstract/document/8577762},
   year = {2018}
}

@inproceedings{RN64,
   author = {Li, Jiarong and Wu, Xiang and Li, Qiuying and Li, Yefeng},
   title = {Observer-based decentralized event-triggered consensus for leader-following linear multi-agent systems},
   booktitle = {2018 IEEE 3rd Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)},
   pages = {1969-1973},
   abstract = {This paper studies the consensus problem for gen-erallinear MASs under directed graphs that full-state measurements are not available. Based on output feedback, we propose an observer-based event-triggered controller to achieve consensus. Each agent only needs to monitor its own output feedback by its observer continuously and updates its controllers and broadcast it to its out-neighbors when it triggers an event or receives new information from its in-neighbors. It is proved that the MAS reaches consensus for all initial conditions and no Zeno behavior exhibits. Furthermore, when there exists a leader, the proposed control protocol can also lead all the followers to track the leader's state. At last, simulation is given to show the theoretical analysis and illustrate the effectiveness of the proposed controll methods.},
   keywords = {Consensus, Decentralized event-triggering, Multi-Agent System, General linear dynamics, Observer-based output feedback},
   ISBN = {2381-0947},
   DOI = {10.1109/IAEAC.2018.8577674},
   url = {https://ieeexplore.ieee.org/abstract/document/8577674},
   year = {2018}
}

@inproceedings{RN57,
   author = {Li, Jiarong and Xie, Zixuan and Liang, Chenxin and Xu, Chihan and Ge, Changshuo and Xu, Zhancong and Wang, Jingyang and Ruan, Liguang and Gui, Weihua and Liang, Xiaojun},
   title = {Indoor health monitoring with VLC-based passive posture monitoring},
   booktitle = {2024 Photonics & Electromagnetics Research Symposium (PIERS)},
   pages = {1-8},
   abstract = {With the growing emphasis on maintaining wellness without disrupting daily routines, the demand for natural indoor health monitoring solutions has never been more pertinent. Traditional health monitoring methods, such as camera-based systems, wearable devices, millimeter-wave, and Wi-Fi technologies, face challenges like privacy concerns, inconvenient wearability, and susceptibility to interference due to crowded frequency bands. Addressing these issues, we designed an integrated system that combines communication, sensing, lighting, and health applications using visible light communication (VLC) technology, achieving non-intrusive and passive human indoor posture and activity monitoring. Firstly, a low-cost VLC device is deployed for systematic basic functionality. A low-powered chip for data acquisition and processing is also designed to analyze modulated light signals reflected off or obstructed by individuals. Furthermore, an optical human posture and activity recognition model is developed to analyze VLC signals captured by receivers. The system employs a streamlined algorithm for signal analysis, incorporating preprocessing steps like filtering, normalization, and downsampling to enhance data quality. Three machine learning models are used for classification: Random forest, decision tree, and support vector machines (SVM), emphasizing prediction accuracy and computational efficiency in real-time monitoring. The monitoring signals and analyzing results are transmitted wirelessly to a user-friendly app on a smartphone. The experimental results demonstrate that our system achieves an accuracy rate exceeding 90% in the detection and monitoring of human postures and activities. The results suggest that our VLC-based system can achieve real-time, affordable, non-intrusive, scalable, and effective indoor posture and activity monitoring. This system has diverse applications for health monitoring in smart homes and healthcare facilities.},
   ISBN = {2831-5804},
   DOI = {10.1109/PIERS62282.2024.10618552},
   year = {2024}
}

@article{RN59,
   author = {Li, Jiarong and Xie, Zixuan and Wang, Zihan and Lin, Zenan and Lu, Chengyue and Zhao, Zihao and Jin, Yuchao and Yin, Jihong and Mu, Shilong and Zhang, Chaobo and Gui, Weihua and Liang, Xiaojun and Wang, Jiyu and Ding, Wenbo},
   title = {A triboelectric gait sensor system for human activity recognition and user identiﬁcation},
   journal = {Nano Energy},
   volume = {112},
   pages = {108473},
   abstract = {Floor-based sensing systems to monitor human activities and identify users are essential for smart homes and intelligent buildings. A low-cost, easy-to-fabricate, and flexible gait sensor system based on triboelectric nanogenerator (TENG) is presented in this paper, which can transform gait movements, even in the low-frequency form, into electrical impulses without an external power source. To realize this, a TENG-based gait sensor unit with an optimized structure design is proposed to enhance the sensing sensitivity. A sensing insole module is formed by arranging the sensor units according to the foot pressure distribution. The sensor distribution is then explored and improved by comparative studies of gait recognition performance, which increases the recognition efficiency and the possible application in edge computing scenarios. Furthermore, a deep learning network is developed based on long short-term memory (LSTM) and residual units to extract deep features from multichannel time-series gait data to boost recognition performance. Experimental results demonstrate that the proposed gait sensor system can be utilized for human activity recognition and user identification with accuracies of 97.9 % and 99.4 %, respectively. Finally, a gait-sensing-based fitness exercise monitoring system is constructed that can estimate calorie expenditure and distinguish between standard and non-standard fitness activities with an accuracy of 97.2 %. This work can be extended to various application scenarios such as security surveillance, health monitoring, and intelligent control, which provides a new ubiquitous self-powered sensing solution for the Internet of Things (IoT).},
   keywords = {Triboelectric nanogenerator, Self-powered sensor, Gait recognition system, Deep learning network, Activity monitoring, User identification},
   ISSN = {2211-2855},
   DOI = {https://doi.org/10.1016/j.nanoen.2023.108473},
   url = {https://www.sciencedirect.com/science/article/pii/S2211285523003105},
   year = {2023}
}

@inproceedings{RN50,
   author = {Li, Jiarong and Xu, Qinghao and Xu, Zhancong and Ge, Changshuo and Ruan, Liguang and Liang, Xiaojun and Ding, Wenbo and Gui, Weihua and Zhang, Xiao-Ping},
   title = {PowerGest: Self-powered gesture recognition for command input and robotic manipulation},
   booktitle = {2024 IEEE 30th International Conference on Parallel and Distributed Systems (ICPADS)},
   pages = {528-535},
   abstract = {As human-computer interaction (HCI) advances, gesture recognition has emerged as a transformative technology for human-computer interaction. Traditional methods, often camera or glove-based, are restricted by various environmental conditions and user-specific demands, highlighting the need for more universal, non-intrusive, and sustainable solutions. Addressing this, we present PowerGest, a self-powered gesture recognition system based on a solar cell array. This innovative system leverages the dual functionalities of solar cells: energy harvesting and gesture sensing, providing an alternative to conventional methods. It integrates a designed low-powered data acquisition chip with a wireless transmission module and a user-friendly interface. PowerGest employs a series of signal processing methods and utilizes several machine learning algorithms, achieving over 97% accuracy for both numeric input and activity control gesture recognition tasks. With its broad applications in robotic control, text input, and more, PowerGest contributes to a more sustainable and intuitive HCI experience. Project demo: https://drive.google.com/drive/folders/10KEul8PAfvTUomi0JvZ8u411JyScCXQI?usp=sharing.},
   keywords = {visible light sensing, gesture recognition, energy harvesting, human-computer interaction},
   ISBN = {2690-5965},
   DOI = {10.1109/ICPADS63350.2024.00075},
   year = {2024}
}

@inproceedings{RN52,
   author = {Li, Jiarong and Xu, Qinghao and Zhu, Qingyang and Xie, Zixuan and Xu, Zhancong and Ge, Changshuo and Ruan, Liguang and Fu, HY and Liang, Xiaojun and Ding, Wenbo},
   title = {Demo: SolarSense: A self-powered ubiquitous gesture recognition system for industrial human-computer interaction},
   booktitle = {Proceedings of the 22nd Annual International Conference on Mobile Systems, Applications and Services},
   publisher = {Association for Computing Machinery},
   pages = {600–601},
   abstract = {SolarSense is a self-powered sensing system for gesture recognition using solar cell arrays, thereby offering a sustainable approach to human-computer interaction (HCI) within industrial settings. The system effectively employed the sensing and energy harvesting capabilities of solar cells, achieving over 97.0\% accuracy in recognizing diverse gestures. The design incorporates a low-power wireless data acquisition chip, a signal processing framework, and a user interface to realize robotic control and text input applications. SolarSense enhances HCI with its eco-friendly and user-centric approach, which is suitable for Internet of things (IoT) scenarios. Demo: https://youtu.be/RmPolChw_c4.},
   keywords = {visible light sensing, gesture recognition, energy harvesting, humancomputer interaction},
   DOI = {10.1145/3643832.3661838},
   url = {https://doi.org/10.1145/3643832.3661838},
   year = {2024}
}

@article{RN60,
   author = {Liang, Chenxin and Li, Jiarong and Liu, Sicong and Yang, Fang and Dong, Yuhan and Song, Jian and Zhang, Xiao-Ping and Ding, Wenbo},
   title = {Integrated sensing, lighting and communication based on visible light communication: A review},
   journal = {Digital Signal Processing},
   volume = {145},
   pages = {104340},
   abstract = {As wireless communication rapidly evolves and the demand for intelligent connectivity grows, the need for precise sensing integrated with efficient communication becomes paramount. While traditional Integrated Sensing and Communication (ISAC) methods have laid foundational groundwork, they grapple with environmental limitations and significant propagation losses. Visible Light Communication (VLC) emerges as a transformative solution characterized by its high-speed transmission, minimal latency, cost-efficiency, and seamless installation. This paper introduces the Lighting, Sensing, and Communication (LiSAC) concept for VLC and systematically reviews the technical aspects, such as channel characteristics, modulation techniques, and system design. Specifically, this paper presents the evolution of the LiSAC system, its integration with other communication technologies, its applications in various fields, and its challenges. At the end of this paper, we outlooked LiSAC in the future, in which high-quality communication will integrate pinpoint sensing accuracy.},
   keywords = {Visible light communication, Visible light sensing, Integrated sensing and communication},
   ISSN = {1051-2004},
   DOI = {https://doi.org/10.1016/j.dsp.2023.104340},
   url = {https://www.sciencedirect.com/science/article/pii/S1051200423004359},
   year = {2024}
}

@inproceedings{RN51,
   author = {Liang, Xiaojun and Li, Jiarong and Xu, Chihan and Xie, Zixuan and Zhang, Chaobo and Ding, Wenbo and Gui, Weihua},
   title = {Gesture recognition and control based on visible light communication},
   booktitle = {2024 43rd Chinese Control Conference (CCC)},
   pages = {6164-6169},
   abstract = {The evolution of human-computer interaction (HCI), particularly in the era of the Internet of Things (IoT), demands innovative solutions that transcend traditional interfaces like keyboards and touchscreens. This study introduces a visible light communication (VLC) based sensing system for non-contact gesture recognition in HCI. The system utilizes a cost-effective VLC setup optimized for indoor environments, ensuring precise signal transmission and reception. The data acquisition and processing board can accurately capture and analyze light-based hand gesture signals. This process is supported by a comprehensive signal processing framework that includes data preprocessing steps and robust machine learning algorithms. These algorithms are designed to detect subtle light pattern variations due to gestures, ensuring an accurate and responsive recognition process. The system’s effectiveness is confirmed by its high gesture recognition accuracy of 95.7%. The study’s key contributions include the development of a VLC-based system for gesture recognition and control, the integration of diverse signal processing techniques suitable for VLC-based data, and the successful demonstration of the system’s practical application through extensive experimental evaluations. These evaluations have validated the system’s efficacy in real-world scenarios, marking an advancement in VLC-enabled HCI. The research highlights VLC’s potential as a user-friendly and efficient interface in HCI, offering more intuitive and responsive interactions in smart environments.},
   keywords = {Visible Light Communication, Gesture Recognition, Human-Computer Interaction, Machine Learning},
   ISBN = {1934-1768},
   DOI = {10.23919/CCC63176.2024.10661455},
   year = {2024}
}

@inproceedings{RN49,
   author = {Wang, Hao and Zhang, Chaobo and Kang, Wenxiong and Liang, Xiaojun and Li, Jiarong and Yang, Chunhua and Gui, Weihua},
   title = {CRPE-MViT: An enhanced transformer model with circular relative positional encoding for the condition identification of zinc oxide rotary kiln},
   booktitle = {Proceedings of the 2024 8th International Conference on Computer Science and Artificial Intelligence},
   publisher = {Association for Computing Machinery},
   pages = {139–146},
   abstract = {Zinc oxide rotary kiln is an important equipment in the recovery process of zinc smelting. Accurate identifying its operating condition is crucial to ensure their efficiency and safety. Traditional methods rely on operator’s experience, which can be inconsistent and suboptimal due to the kiln’s dynamic environment and the varying skill levels of operators. To addres this issue, this paper introduces a novel condition identification approach that integrates Circular Relative Positional Encoding (CRPE) with a lightweight Mobile Vision Transformer (MobileViT) network. The specifically designed CRPE module takes into account the shape characteristics of the kiln and the rotational motion mechanism, and MobileViT provides a lightweight network structure. The resulting prediction model, CRPE-MobileViT (CRPE-MViT), significantly reduces the number of parameters while maintaining high accuracy. Experiments on a real large rotary kiln shown that the CRPE-MViT effectively identifies kiln conditions with an overall accuracy of 92.40%. Specifically, for the classification of normal-fired condition, the model achieved a precision of 92.21% and a recall of 97.25%, providing a reliable solution for real-time monitoring in industrial settings.},
   keywords = {Zinc Oxide Rotary Kiln, Condition Identification, Flame image, Circular Relative Position Encoding, MobileViT},
   DOI = {10.1145/3709026.3709095},
   url = {https://doi.org/10.1145/3709026.3709095},
   year = {2025}
}

@article{RN62,
   author = {Wang, Zihan and Li, Jiarong and Jin, Yuchao and Wang, Jiyu and Yang, Fang and Li, Gang and Ni, Xiaoyue and Ding, Wenbo},
   title = {Sensing beyond itself: Multi-functional use of ubiquitous signals towards wearable applications},
   journal = {Digital Signal Processing},
   volume = {116},
   pages = {103091},
   abstract = {Wearable technologies provide a non-invasive way to monitor user's activity, identity, and health in real-time, which have attracted tremendous interests from both academia and industry. Due to constraints in form factor and power consumption, the sensing capabilities and functionalities of the wearables are usually limited by the available sensors. In the past decade, researchers have committed to realizing the sensing capability of multiple sensors via the signal from one sensor, which expanded the functionalities and sensing domains of traditional sensors. For the first time, we defined such sensing approach as “cross-sensing” and provided a comprehensive review on the cross-sensing towards wearable applications (i.e., human-machine interface, health services, and security). Specifically, this paper summarized the applied signal processing and machine learning algorithms, and discussed how cross-sensing would affect the development and innovation trends of wearable electronics.},
   keywords = {Wearable technologies
Ubiquitous sensing
Human-machine interaction
Health and safety
Security},
   ISSN = {1051-2004},
   DOI = {https://doi.org/10.1016/j.dsp.2021.103091},
   url = {https://www.sciencedirect.com/science/article/pii/S1051200421001305},
   year = {2021}
}

@inproceedings{RN55,
   author = {Xu, Z. and Liang, C. and Wang, J. and Ruan, L. and Li, J. and Dong, Y. and Ding, W. and Song, J.},
   title = {LiFall: Passive indoor fall detection system based on illumination and visible light communication networks},
   booktitle = {2024 Photonics & Electromagnetics Research Symposium (PIERS)},
   pages = {1-8},
   abstract = {Effective fall detection is a critical component of indoor health monitoring for individuals. The most widely used wearable devices are not convenient, especially for the elderly. Another approach of passive solutions usually use RGB camera, millimeter-wave radar, or WiFi. However, they bring about issues of privacy infringement and/or electromagnetic interference. Among them, visible light-based systems can avoid these issues, however, they require customized light sources and highly sensitive receivers, making it expensive for deployment. Motivated by these previous works, we aim to design a passive, low-invasiveness, and low-cost fall detection system. In this work, we propose LiFall, a passive fall detection system based on illumination and visible light communication (VLC) networks, which eliminates the need for hardware modifications to current devices. LiFall detects human falls by analyzing the intensity variation of the received optical signals captured by the low-cost photodetectors. Subsequently, we propose an innovative signal segmentation algorithm tailored for accurately segmenting human activities in the time series. Compared to existing double-window segmentation schemes, our method enhances the signal integrity by 20%. In order to identify falls, we analyze the temporal statistical features and waveform characteristics derived from human activity signals and adopt the lightweight classifiers of support vector machines (SVM) and random forests (RF) for fall detection. We deploy LiFall system in various typical indoor scenarios and collect human fall and other daily activity data for system performance evaluation. Experimental results demonstrate that LiFall is able to achieve a fall detection accuracy exceeding 90% in different typical indoor settings without compromising illumination and communication.},
   ISBN = {2831-5804},
   DOI = {10.1109/PIERS62282.2024.10618192},
   year = {2024}
}
